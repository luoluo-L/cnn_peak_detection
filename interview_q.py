# Interview Question:
#
# You are given a signal that contains two peaks. The signal is generated by
# adding two peaks with ramps and a complex noise signal composed of multiple
# sine waves. Your task is to implement a neural network that predicts the positions
# of the two peaks and the midpoint between them.
#
# The predictions should be output as a tensor of shape (batch_size, 3) where each
# row contains the predicted positions of the first peak, midpoint, and second peak.
# The final results should be visualized using the provided plotting code.
#
# Notes:
# - You may modify the hyper parameters, model architecture, and training loop.
# - You may add preprocessing steps if necessary.
# - You may add to the visualization code, but do not remove the existing plots.
# - Do not update the signal generation or batch generation code.
# - The solution should implemented as a neural network, not manual feature detection.

import matplotlib.pyplot as plt
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim


# additional dependencies
from scipy.signal import spectrogram
from scipy.signal import butter, freqs
import torch.nn.functional as F
import os
import csv
from torchsummary import summary

# hyper parameters
num_epochs = 1000
batch_size = 128 #32 # larger batch size seems to have better training performance
learning_rate = 0.01 # smaller loss # 0.0001

length = 2048  # length of signal: 2s chuncks
sampling_rate = 1024  # sampling freq
num_predictions = batch_size #32


savefoldername = "experiment_run1"
savefolder_features = "visualization_features"

plot_samples = False

# File path for the CSV file
csv_file_path = os.path.join(savefoldername,  
'example_result.csv')


if not os.path.exists(savefoldername):
    os.mkdir(savefoldername)

if not os.path.exists(savefolder_features):
    os.mkdir(savefolder_features)

class ThreeLayerCNN1D(nn.Module):
    def __init__(self):
        super(ThreeLayerCNN1D, self).__init__()
        # Layer 1
        self.conv1 = nn.Conv1d(in_channels=65, out_channels=64, kernel_size=3, stride=1, padding=1)
        self.bn1 = nn.BatchNorm1d(64)
        
        # Layer 2
        self.conv2 = nn.Conv1d(in_channels=64, out_channels=32, kernel_size=3, stride=1, padding=1)
        self.bn2 = nn.BatchNorm1d(32)
        
        # Layer 3
        self.conv3 = nn.Conv1d(in_channels=32, out_channels=16, kernel_size=3, stride=1, padding=1)
        self.bn3 = nn.BatchNorm1d(16)
        
        # Pooling
        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)
        
        # Fully connected layers
        self.fc1 = nn.Linear(16 * (31 // 2 // 2 // 2), 20)  # After 3 layers of pooling
        self.fc2 = nn.Linear(20, 3)  # Output layer for 3 classes


        #self.dropout = nn.Dropout(0.8)

    def forward(self, x):
        # First convolutional block
        x = F.relu(self.bn1(self.conv1(x)))
        #x = self.dropout(x)
        x = self.pool(x)
        
        # Second convolutional block
        x = F.relu(self.bn2(self.conv2(x)))
        #x = self.dropout(x)
        x = self.pool(x)
        
        # Third convolutional block
        x = F.relu(self.bn3(self.conv3(x)))
        #x = self.dropout(x)
        x = self.pool(x)
        
        # Flatten
        x = torch.flatten(x, start_dim=1)
        
        # Fully connected layers
        x = F.relu(self.fc1(x))
        x = self.fc2(x)  # Output layer
        return x


class PeakDetectionNet(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        # TODO: Implement the model architecture
        self.fc_layer = nn.Linear(2048, 3)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        # TODO: Implement the forward pass
        x = self.fc_layer(x).view(batch_size, -1)
        return x


# Generate a signal with two peaks
def generate_signal(
    p1_position: float,
    p2_position: float,
    p1_amplitude: float,
    p2_amplitude: float,
    length: int,
    sampling_rate: int,
    add_complex_signal: bool = True,
) -> torch.Tensor:
    signal = np.zeros(length)

    peak1_width = np.random.randint(10, 40)
    peak2_width = np.random.randint(10, 40)

    peak1_idx = int(p1_position * sampling_rate)
    peak2_idx = int(p2_position * sampling_rate)

    # Add peaks with ramps
    signal[peak1_idx - peak1_width : peak1_idx + peak1_width] = p1_amplitude * np.hanning(peak1_width * 2)
    signal[peak2_idx - peak2_width : peak2_idx + peak2_width] = p2_amplitude * np.hanning(peak2_width * 2)

    # Add complex noise signal composed of multiple sine waves
    if add_complex_signal:
        complex_signal = np.zeros(length)
        num_sine_waves = np.random.randint(2, 5)

        for _ in range(num_sine_waves):
            frequency = np.random.uniform(1, 10)
            amplitude = np.random.uniform(0.05, 0.2)
            phase = np.random.uniform(0, 2 * np.pi)
            sine_wave = amplitude * np.sin(
                2 * np.pi * frequency * np.linspace(0, length / sampling_rate, length) + phase
            )
            complex_signal += sine_wave

        signal += complex_signal

    return torch.tensor(signal, dtype=torch.float32)

###########


"""

from scipy.signal import butter, lfilter

def butter_bandpass(lowcut, highcut, fs, order=5):
    return butter(order, [lowcut, highcut], fs=fs, btype='band')

def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):
    b, a = butter_bandpass(lowcut, highcut, fs, order=order)
    y = lfilter(b, a, data)
    return y


def filter_signal(signal):
    
    y = butter_bandpass_filter(signal, lowcut= 0.1, highcut = 100, fs = sampling_rate, order=6)
    plt.figure()
    plt.plot(signal)
    plt.plot(y, label='Filtered signal')
    plt.xlabel('time (seconds)')
    plt.show()

    return y
"""

def generate_spectrogram(signal, plotting = False, i = 0):
    """
    generate spectrogram of signal 
    """
    # 128,128,64
    f, t_spectrogram, Sxx = spectrogram(signal, fs=sampling_rate, nfft = 128, nperseg=128,noverlap = 64)

    if plotting:
        # Create subplots
        fig, axs = plt.subplots(2, 1, figsize=(10, 8), sharex=True)  # Two rows, one column, shared x-axis
        t = np.arange(length)/sampling_rate

        # Plot the signal
        axs[0].plot(t, signal, color='blue')
        axs[0].set_title('Signal')
        axs[0].set_ylabel('Amplitude')
        axs[0].set_xlim([0,t[-1]])
        axs[0].grid(True)

        # Plot the spectrogram
        pcm = axs[1].pcolormesh(t_spectrogram, f, Sxx, shading='gouraud')
        axs[1].set_title('Spectrogram')
        axs[1].set_xlabel('Time [sec]')
        axs[1].set_ylabel('Frequency [Hz]')
        #fig.colorbar(pcm, ax=axs[1], label='Intensity [dB]')

        # Adjust layout
        plt.tight_layout()
        plt.savefig(os.path.join(savefolder_features, "Features_"+str(i)+ ".png" ))
        #plt.show()
    return Sxx


def generate_batch(
    length: int,
    sampling_rate: int,
    batch_size: int,
) -> tuple[torch.Tensor, torch.Tensor]:
    signals = []
    targets = []

    for _ in range(batch_size):
        peak1_time = np.random.uniform(0.1, 0.5)
        peak2_time = np.random.uniform(0.6, 1.8)
        signal = generate_signal(
            p1_position=peak1_time,
            p1_amplitude=1.0,
            p2_position=peak2_time,
            p2_amplitude=0.8,
            length=length,
            sampling_rate=sampling_rate,
        )
        signal = (signal - signal.mean()) / signal.std()

        peak1_sample = peak1_time * sampling_rate / length
        peak2_sample = peak2_time * sampling_rate / length
        midpoint_sample = (peak1_time + peak2_time) / 2 * sampling_rate / length

        #y = filter_signal(signal)
        #Sxx = generate_spectrogram(signal)

        #print(Sxx.shape)
        #print(target.shape)
        signals.append(signal)
        targets.append(torch.tensor([peak1_sample, midpoint_sample, peak2_sample], dtype=torch.float32))

    # signals, [peak1, midpoint, peak2]
    return torch.stack(signals).unsqueeze(1), torch.stack(targets)



def generate_preprocess_data(signals_torch_sensors,  plotting = False):
    signals_numpy = signals_torch_sensors.detach().cpu().numpy()
    #print(signals_numpy.shape)  # [batchsize, 1, signal_length]

    spectrograms = []
    for cur_batch_idx in np.arange(batch_size):

        cur_signal = signals_numpy[cur_batch_idx,:,:].flatten()
        cur_spectrogram = generate_spectrogram(cur_signal, plotting = plotting, i = cur_batch_idx)
        #print(cur_spectrogram.shape)
 
        spectrograms.append(torch.tensor(cur_spectrogram, dtype=torch.float32))

    return torch.stack(spectrograms)#.unsqueeze(1)



def main() -> None:
    # define model / training parameters
    #model = PeakDetectionNet()
    #model.train()

    model = ThreeLayerCNN1D()
    print(model)
    #input_dim = (128, 65, 31)
    #summary(model, input_dim)

    pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

    print("total number of parameters in the model")
    print(pytorch_total_params)
    model.train()

    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)

    # training loop

    loss_func_value_list= []
    epoch_array= []
    for epoch in range(num_epochs):
        signals, targets = generate_batch(length=length, sampling_rate=sampling_rate, batch_size=batch_size)
        out_spectrogram = generate_preprocess_data(signals)
        
        #print(out_spectrogram.shape)
        optimizer.zero_grad()
        outputs = model(out_spectrogram)
        
        loss = criterion(outputs, targets)
        loss.backward()
        optimizer.step()

        #print("out spectra shape")
        #print(out.shape)

        #print("Signal and targets shape")
        #print(signals.shape)
        #print(targets.shape)
        
        #optimizer.zero_grad()
        #outputs = model(signals)

        #loss = criterion(outputs, targets)
        #loss.backward()
        #optimizer.step()

        if (epoch + 1) % 50 == 0:
            print(f"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.6f}")
            epoch_array.append(epoch)
            loss_func_value_list.append(loss.item())

    plt.figure()
    plt.plot(epoch_array, loss_func_value_list)
    plt.title("loss function value over epochs")
    plt.savefig(os.path.join(savefoldername,"loss_func_epochs.png"))

    if plot_samples:
        plt.show()
    # predictions
    signals, targets = generate_batch(length=length, sampling_rate=sampling_rate, batch_size=num_predictions)
    out_spectrogram = generate_preprocess_data(signals, plotting = True)

    model.eval()

    with torch.no_grad():
        predictions = model(out_spectrogram)

    #with torch.no_grad():
    #    predictions = model(signals)
    # generate metrics to evaluate performance

    peak_1_err_sec = []
    midpoint_err_sec = []
    peak_2_err_sec = []

    for i in range(num_predictions):
        error_vector = predictions[i].numpy() - targets[i].numpy()
        error_vector_sec = error_vector *length /sampling_rate
        peak_1_err_sec.append(error_vector_sec[0])
        midpoint_err_sec.append(error_vector_sec[1])
        peak_2_err_sec.append(error_vector_sec[2])

    peak_1_err_sec= np.array(peak_1_err_sec)* 1000.0
    midpoint_err_sec = np.array(midpoint_err_sec) * 1000.0
    peak_2_err_sec = np.array(peak_2_err_sec) * 1000.0


    pk1_mean = np.mean(np.abs(peak_1_err_sec))
    pk1_std = np.std(np.abs(peak_1_err_sec))
    midpt_mean = np.mean(np.abs(midpoint_err_sec))
    midpt_std = np.std(np.abs(midpoint_err_sec))
    pk2_mean = np.mean(np.abs(peak_2_err_sec))
    pk2_std = np.std(np.abs(peak_2_err_sec))


    print("peak 1, midpoint, and peak 2 detection error (ms)")
    print((pk1_mean, pk1_std))
    print((midpt_mean, midpt_std))
    print((pk2_mean, pk2_std))


    results_data = [['Abs Error Mean (peak 1) ms','Abs Error Std (peak 1) ms',  
    'Abs Error Mean (Mid pt) ms','Abs Error Std (Mid pt) ms', 
    'Abs Error Mean (peak 2) ms','Abs Error Std (peak 2) ms'], 
    [pk1_mean, pk1_std, midpt_mean, midpt_std, pk2_mean, pk2_std]
    ]



    # Open the file in write mode
    with open(csv_file_path, mode='w', newline='') as file:
        # Create a csv.writer object
        writer = csv.writer(file)
        # Write data to the CSV file
        writer.writerows(results_data)



    # plot predictions
    for i in range(num_predictions):
        plt.figure(figsize=(10, 4))
        plt.plot(signals[i].squeeze().numpy(), label="Original Signal")
        target_positions = targets[i].numpy() * length
        predicted_pos = predictions[i].numpy() * length

        plt.axvline(x=target_positions[0], color="g", linestyle="-", label="Peak 1")
        plt.axvline(x=target_positions[1], color="g", linestyle="--", label="Midpoint")
        plt.axvline(x=target_positions[2], color="g", linestyle="-", label="Peak 2")

        plt.axvline(x=predicted_pos[0], color="r", linestyle="-", label="Predicted Peak 1")
        plt.axvline(x=predicted_pos[1], color="r", linestyle="--", label="Predicted Midpoint")
        plt.axvline(x=predicted_pos[2], color="r", linestyle="-", label="Predicted Peak 2")

        plt.title(f"Example {i + 1}")
        plt.legend()
        plt.savefig(os.path.join(savefoldername, "prediction_"+str(i)+ ".png" ))

        if plot_samples:
            plt.show()


if __name__ == "__main__":
    main()